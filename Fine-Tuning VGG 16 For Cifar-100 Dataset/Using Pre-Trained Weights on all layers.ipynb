{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-12T17:07:20.839884Z","iopub.status.busy":"2024-04-12T17:07:20.838921Z","iopub.status.idle":"2024-04-12T17:07:21.211575Z","shell.execute_reply":"2024-04-12T17:07:21.210684Z","shell.execute_reply.started":"2024-04-12T17:07:20.839850Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/meta\n","/kaggle/input/file.txt\n","/kaggle/input/test\n","/kaggle/input/train\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# Transforming data"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T17:07:21.213459Z","iopub.status.busy":"2024-04-12T17:07:21.213091Z","iopub.status.idle":"2024-04-12T17:07:24.315593Z","shell.execute_reply":"2024-04-12T17:07:24.314657Z","shell.execute_reply.started":"2024-04-12T17:07:21.213432Z"},"trusted":true},"outputs":[],"source":["import torch \n","import torchvision\n","\n","\n","transform_train = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(224),  # Resize to 256x256\n","    #torchvision.transforms.CenterCrop(64),  # Crop a central 224x224 region\n","    #torchvision.transforms.RandomResizedCrop(size=(64,64), scale=(0.8, 1.0)),  # Randomly resize and crop\n","    torchvision.transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip horizontally\n","    torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","    torchvision.transforms.ToTensor(),  # Convert to PyTorch tensor\n","    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ImageNet\n","])\n","\n","transform_test=torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(224),  \n","    torchvision.transforms.ToTensor(),  # Convert to PyTorch tensor\n","    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"markdown","metadata":{},"source":["# Importing and Loading Data "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T17:07:24.317165Z","iopub.status.busy":"2024-04-12T17:07:24.316802Z","iopub.status.idle":"2024-04-12T17:07:26.112180Z","shell.execute_reply":"2024-04-12T17:07:26.111144Z","shell.execute_reply.started":"2024-04-12T17:07:24.317142Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["from torch.utils.data import Dataset, DataLoader\n","from torchvision.datasets import CIFAR100\n","\n","root=\"./data\"\n","train = CIFAR100(root=root, transform=transform_train,download=True,train=True)\n","test= CIFAR100(root=root, transform=transform_test,download=True,train=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Initialize Dataloader"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T17:07:26.114490Z","iopub.status.busy":"2024-04-12T17:07:26.114208Z","iopub.status.idle":"2024-04-12T17:07:26.119346Z","shell.execute_reply":"2024-04-12T17:07:26.118408Z","shell.execute_reply.started":"2024-04-12T17:07:26.114466Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train, batch_size=100, shuffle=True)\n","test_loader= DataLoader(test, batch_size=16, shuffle=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T17:07:26.121252Z","iopub.status.busy":"2024-04-12T17:07:26.120661Z","iopub.status.idle":"2024-04-12T17:07:26.132243Z","shell.execute_reply":"2024-04-12T17:07:26.131464Z","shell.execute_reply.started":"2024-04-12T17:07:26.121219Z"},"trusted":true},"outputs":[{"data":{"text/plain":["500"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(train_loader)"]},{"cell_type":"markdown","metadata":{},"source":["# Importing torch"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T17:07:26.133611Z","iopub.status.busy":"2024-04-12T17:07:26.133327Z","iopub.status.idle":"2024-04-12T17:07:26.145973Z","shell.execute_reply":"2024-04-12T17:07:26.145114Z","shell.execute_reply.started":"2024-04-12T17:07:26.133587Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\nclass VGG16(nn.Module):\\n    def __init__(self, num_classes=10):\\n        super(VGG16, self).__init__()\\n        self.layer1 = nn.Sequential(\\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(64),\\n            nn.ReLU())\\n        self.layer2 = nn.Sequential(\\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(64),\\n            nn.ReLU(), \\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\\n        self.layer3 = nn.Sequential(\\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(128),\\n            nn.ReLU())\\n        self.layer4 = nn.Sequential(\\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(128),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\\n        self.layer5 = nn.Sequential(\\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(256),\\n            nn.ReLU())\\n        self.layer6 = nn.Sequential(\\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(256),\\n            nn.ReLU())\\n        self.layer7 = nn.Sequential(\\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(256),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\\n        self.layer8 = nn.Sequential(\\n            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(512),\\n            nn.ReLU())\\n        self.layer9 = nn.Sequential(\\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(512),\\n            nn.ReLU())\\n        self.layer10 = nn.Sequential(\\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(512),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\\n        self.layer11 = nn.Sequential(\\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(512),\\n            nn.ReLU())\\n        self.layer12 = nn.Sequential(\\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(512),\\n            nn.ReLU())\\n        self.layer13 = nn.Sequential(\\n            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\\n            nn.BatchNorm2d(512),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size = 2, stride = 2))\\n            \\n        \\n        self.fc = nn.Sequential(\\n            nn.Dropout(0.5),\\n            nn.Linear(7*7*512, 4096),\\n            nn.ReLU())\\n        \\n        self.fc1 = nn.Sequential(\\n            nn.Dropout(0.5),\\n            nn.Linear(4096, 4096),\\n            nn.ReLU())\\n        self.fc2= nn.Sequential(\\n            nn.Linear(4096, num_classes))\\n        \\n    def forward(self, x):\\n        out = self.layer1(x)\\n        #print(out.shape)\\n        out = self.layer2(out)\\n        #print(out.shape)\\n        out = self.layer3(out)\\n        #print(out.shape)\\n        out = self.layer4(out)\\n        #print(out.shape)\\n        out = self.layer5(out)\\n        #print(out.shape)\\n        out = self.layer6(out)\\n        #print(out.shape)\\n        out = self.layer7(out)\\n        #print(out.shape)\\n        out = self.layer8(out)\\n        #print(out.shape)\\n        out = self.layer9(out)\\n        #print(out.shape)\\n        out = self.layer10(out)\\n        #print(out.shape)\\n        out = self.layer11(out)\\n        #print(out.shape)\\n        out = self.layer12(out)\\n        #print(out.shape)\\n        out = self.layer13(out)\\n        #print(out.shape)\\n    \\n        out=out.flatten(start_dim=1)\\n        #print(out.shape)\\n        out = self.fc(out)\\n        #print(out.shape)\\n        \\n        out = self.fc1(out)\\n        #print(out.shape)\\n        out = self.fc2(out)\\n        #print(out.shape)\\n        \\n        return out\\n        '"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import torch.nn as nn\n"]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameter tuning and  Defining Model Architecture"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T17:07:26.147420Z","iopub.status.busy":"2024-04-12T17:07:26.147078Z","iopub.status.idle":"2024-04-12T17:07:28.068863Z","shell.execute_reply":"2024-04-12T17:07:28.068068Z","shell.execute_reply.started":"2024-04-12T17:07:26.147389Z"},"trusted":true},"outputs":[],"source":["import torchvision.models as models\n","device='cuda'\n","num_classes = 100\n","num_epochs = 2\n","learning_rate = 0.001\n","model = models.vgg16(weights='VGG16_Weights.DEFAULT')\n","#model=nn.DataParallel(model)\n","\n","\n","# Replace the last classifier layer\n","num_features_in = model.classifier[-1].in_features  # Get input size of the last layer\n","model.classifier[-1] = torch.nn.Linear(num_features_in,100)\n","model=model.to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.7)  \n","\n","\n","# Train the model\n","total_step = len(train_loader)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T17:07:28.070175Z","iopub.status.busy":"2024-04-12T17:07:28.069922Z","iopub.status.idle":"2024-04-12T17:07:28.076116Z","shell.execute_reply":"2024-04-12T17:07:28.075288Z","shell.execute_reply.started":"2024-04-12T17:07:28.070152Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=25088, out_features=4096, bias=True)\n","  (1): ReLU(inplace=True)\n","  (2): Dropout(p=0.5, inplace=False)\n","  (3): Linear(in_features=4096, out_features=4096, bias=True)\n","  (4): ReLU(inplace=True)\n","  (5): Dropout(p=0.5, inplace=False)\n","  (6): Linear(in_features=4096, out_features=100, bias=True)\n",")"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["model.classifier"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T17:07:28.077440Z","iopub.status.busy":"2024-04-12T17:07:28.077200Z","iopub.status.idle":"2024-04-12T17:07:28.087247Z","shell.execute_reply":"2024-04-12T17:07:28.086309Z","shell.execute_reply.started":"2024-04-12T17:07:28.077419Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<bound method Module.parameters of VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=100, bias=True)\n","  )\n",")>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["model.parameters"]},{"cell_type":"markdown","metadata":{},"source":["# Traning and Testing loop"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T17:07:28.090084Z","iopub.status.busy":"2024-04-12T17:07:28.089711Z","iopub.status.idle":"2024-04-12T17:24:05.001281Z","shell.execute_reply":"2024-04-12T17:24:05.000314Z","shell.execute_reply.started":"2024-04-12T17:07:28.090060Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [07:40<00:00,  1.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss 1.8397932052612305\n","Accuracy of the network on the 5000  images: 45.0 %\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:38<00:00, 16.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" Loss Minimum inf Loss_current 1103.7502732276917\n","Accuracy of the network on the 5000 validation images: 50.25 %\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [07:38<00:00,  1.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Loss 1.3759379386901855\n","Accuracy of the network on the 5000  images: 59.0 %\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 625/625 [00:38<00:00, 16.26it/s]"]},{"name":"stdout","output_type":"stream","text":[" Loss Minimum 1103.7502732276917 Loss_current 891.5986252427101\n","Accuracy of the network on the 5000 validation images: 58.96 %\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from tqdm import tqdm\n","total_step = len(train_loader)\n","patience=2\n","patience_count=0\n","minimum_loss=float('inf')\n","\n","for epoch in range(num_epochs):\n","    \n","    for  images, labels in tqdm(train_loader):  \n","        correct = 0\n","        total = 0\n","        # Move tensors to the configured device\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        model.train()\n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        \n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Loss {loss.item()}\" )\n","    print('Accuracy of the network on the {}  images: {} %'.format(50000, 100 * correct / total))\n","        \n","    # Validation\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        eval_loss=0\n","        for images, labels in tqdm(test_loader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            \n","            eval_loss+=criterion(outputs, labels).item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            del images, labels, outputs\n","        print(f\" Loss Minimum {minimum_loss} Loss_current {eval_loss}\")\n","            \n","        if eval_loss<=minimum_loss:\n","            patience_count=0\n","            minimum_loss=eval_loss\n","        else:\n","            patience_count+=1\n","            print(f\"Patience Counter {patience_count}\")\n","        print('Accuracy of the network on the {} validation images: {} %'.format(10000, 100 * correct / total))\n","        \n","        if patience_count>=patience:\n","            print(f\"Early stopping initialized\")\n","            break\n"]},{"cell_type":"markdown","metadata":{},"source":["# Passing Radnom image to find Cnn output"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-12T17:26:50.817142Z","iopub.status.busy":"2024-04-12T17:26:50.816776Z","iopub.status.idle":"2024-04-12T17:26:50.829581Z","shell.execute_reply":"2024-04-12T17:26:50.828627Z","shell.execute_reply.started":"2024-04-12T17:26:50.817115Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([1, 100])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model = model.to(device)\n","a=torch.randn(1,3,224,224)\n","a=a.to(device)\n","#center_crop = torchvision.transforms.CenterCrop(64)\n","\n","# Apply the center cropping transform to the input image\n","#a = center_crop(a)\n","\n","x=model(a)\n","x.shape"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1059701,"sourceId":1782442,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
